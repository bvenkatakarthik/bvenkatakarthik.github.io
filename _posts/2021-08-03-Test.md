---
layout: post
title: "Test"
author: "Karthik"
categories: journal
tags: [documentation,sample]
---

Test, $ x^2 \geq 0 $. 

```
def square(x): 
    return x**2 
```

###### 11 

$${ \underline{\textbf{Implicit function theorem}} }$$

Consider complete normed spaces ${ E, F, G , }$ and a ${ C ^p }$ map 

$${ f : U (\subseteq E \times F \text{ open}) \longrightarrow G . }$$ 

It has a zero set

$${ f ^{-1} (0) =  Z _f = \lbrace (x, y) : (x, y) \in U, f(x, y) = 0 \rbrace .  }$$ 

 Let ${ (a, b) \in Z _f . }$ The goal is to study the structure of ${ Z _f }$ near ${ (a, b) .}$    
We can ask ourselves: When does ${ Z _f }$ look like the graph of a function near ${ (a, b) }$? 



**Obs** [Open subsets of ${ E \times F }$]:    
Let ${ E, F }$ be complete normed spaces. Unless otherwise mentioned, ${ E \times F }$ is equipped with the sup norm. Now for ${ (a, b) \in E \times F }$ and ${ \delta > 0 , }$ 

$${ \begin{align*} &\, B((a, b), \delta) \\ = &\, \lbrace (x, y): \max \lbrace \lVert x - a \rVert, \lVert y - b \rVert \rbrace < \delta \rbrace \\ = &\, \lbrace (x, y) : \lVert x - a \rVert < \delta , \lVert y - b \rVert < \delta \rbrace \\ = &\, B(a, \delta) \times B(b, \delta) . \end{align*}  }$$ 

Unions of such open balls make up the open subsets of ${ E \times F . }$    

**Obs**: Let ${ E, F }$ be complete normed spaces, and ${ U, V }$ be open subsets of ${ E, F }$ respectively. Then ${ U \times V }$ is an open subset of ${ E \times F . }$    
**Pf**: Let ${ (a, b) \in U \times V . }$ There are ${ \delta _1, \delta _2 > 0 }$ such that ${ B(a, \delta _1) \subseteq U }$ and ${ B(b, \delta _2) \subseteq V . }$ Considering ${ \delta = \min \lbrace \delta _1, \delta _2 \rbrace > 0 ,  }$ the ball 

$${ \begin{align*} B((a, b), \delta) = &\, B(a, \delta) \times B(b, \delta) \\ \subseteq &\, B(a, \delta _1) \times B(b, \delta _2) \\ \subseteq &\, U \times V  \end{align*}  }$$ 

as needed. ${ \blacksquare }$ 

**Def** [Partial derivatives]:    
Consider complete normed spaces ${ E, F, G, }$ open subsets ${ U \subseteq E, }$ ${ V \subseteq F , }$ and a map 

$${ f : U \times V \, (\subseteq E \times F \text{ open}) \longrightarrow G .   }$$ 

Let ${ (a, b) \in U \times V . }$ If the section 

$${  f ^{b} = f(\cdot, b) : U \longrightarrow G, \quad x \mapsto f(x, b) }$$ 

is differentiable at ${ a , }$ the derivative ${ (Df ^{b} )(a) \in L(E, G) }$ is written as ${ \partial _1 f(a, b) . }$    
Similarly if the section 

$${ f ^{a} = f(a, \cdot) : V \longrightarrow G, \quad y \mapsto f(a, y)   }$$ 

is differentiable at ${ b, }$ the derivative ${ (D f ^{a}) (b) \in L(F, G) }$ is written as ${ \partial _2 f (a, b) . }$ 

**Thm** [${ C ^p }$ maps ${ E \times F \to G }$]:    
Consider complete normed spaces ${ E, F, G, }$ open subsets ${ U \subseteq E, }$ ${ V \subseteq F , }$ and a map 

$${ f : U \times V \, (\subseteq E \times F \text{ open}) \longrightarrow G .   }$$ 

Now ${ f }$ is a ${ C ^p }$ map if and only if the partials 

$${ \partial _1 f : U \times V \longrightarrow L(E, G),  }$$ 

$${ \partial _2 f : U \times V \longrightarrow L(F, G)  }$$ 

exist and are ${ C ^{p-1} . }$    
In this case, for ${ (a, b) \in U \times V  }$ the derivative ${ (Df)(a, b) \in L(E \times F, G)  }$ is given by 

$${ (Df)(a, b) \, (h, k) = \partial _1 f (a, b) \, h + \partial _2 f (a, b) \, k .   }$$ 

**Pf**: ${ \underline{\Rightarrow} }$ Say ${ f }$ is ${ C ^p . }$ We are to show the partials ${ \partial _1 f, }$ ${ \partial _2 f }$ exist and are ${ C ^{p-1} . }$    

Let ${ (a, b) \in U \times V . }$ By definition of derivative, for ${ (h, k) }$ in a neighbourhood of ${ (0,0),  }$

$${ \begin{aligned} &\, f(a+h, b+k) = f(a, b) + Df(a, b) \, (h, k) + \lVert (h, k) \rVert \varphi(h, k) \\ &\, \text{with } \varphi(0, 0) = 0 \text{ and } \varphi \text{ continuous at } (0, 0) .  \end{aligned}  }$$ 

Especially for ${ h }$ in a neighbourhood of ${ 0 , }$

$${ \begin{aligned} &\, f(a+h, b) = f(a, b) + Df(a, b) \, (h, 0) + \lVert h \rVert \varphi (h, 0)  \end{aligned} }$$ 

so the partial derivative ${ \partial _1 f(a, b) \in L(E, G) }$ is given by ${ h \mapsto Df(a, b) \, (h, 0).  }$    

Similarly the partial derivative ${ \partial _2 f(a, b) \in L(F, G) }$ is given by ${ k \mapsto Df (a, b) \, (0, k) . }$    

With this, ${ \partial _1 f(a,  b) }$ and ${ \partial _2 f(a, b) }$ exist, and 

$${ Df (a, b) \, (h, k) = \partial _1 f (a, b) \, h + \partial _2 f (a, b) \, k .   }$$ 

It is left to show that

$${ \partial _1 f : \underbrace{(x, y)} _{\in \, U \times V} \mapsto \underbrace{Df(x, y) \, (\cdot \, , \, 0)} _{\in \, L(E, G)},   }$$ 

$${ \partial _2 f : \underbrace{(x, y)} _{\in \, U \times V} \mapsto \underbrace{Df(x, y) \, (0 \, , \, \cdot)} _{\in \, L(F, G)} }$$ 

are ${ C ^{p-1}  }$ maps. Since 

$${ \alpha _1 : L(E \times F, G) \longrightarrow L(E, G), \quad \alpha _1 (\varphi) = \varphi(\cdot \, , \, 0) }$$ 

$${ \alpha _2 : L(E \times F, G) \longrightarrow L(F, G), \quad \alpha _2 (\varphi) = \varphi(0 , \, \cdot)  }$$ 

are continuous linear, the compositions 

$${ \partial _1 f = \alpha _1 \, \circ \, Df ,  }$$ 

$${ \partial _2 f = \alpha _2 \, \circ Df  }$$ 

are ${ C ^{p-1} }$ maps, as needed.    

${ \underline{\Leftarrow} }$ Say the partials 

$${ \partial _1 f : U \times V \longrightarrow L(E, G), }$$ 

$${ \partial _2 f : U \times V \longrightarrow L(F, G) }$$ 

exist and are ${ C ^{p-1} . }$ We are to show ${ f }$ is a ${ C ^p }$ map. 

Let ${ (a, b) \in U \times V . }$ For ${ (h, k) }$ in a neighbourhood of ${ 0 , }$ 

$${ \begin{aligned} &\, f(a+h, b+k) - f(a, b) - \partial _1 f(a, b) \, h - \partial _2 f(a, b) \, k \\ = &\,  f(a+h, b+k) - f(a, b+k) \\ &\, + f(a, b+k) - f(a, b)  \\ &\, - \partial _1 f(a, b) \, h - \partial _2 f(a, b) \, k \\ = &\, \int _0 ^1  \partial _1 f(a+sh, b+k) \,  h \, ds  \\ &\, + \int _0 ^1 \partial _2 f(a, b + tk) \, k \, dt  \\ &\, - \partial _1 f(a, b) \, h - \partial _2 f(a, b) \, k \\ = &\, \int _0 ^1 [\partial _1 f(a + sh, b+k) - \partial _1 f(a, b)] \, h \, ds \\ &\, + \int _0 ^1 [\partial _2 f(a, b+tk) - \partial _2 f(a, b)] \, k \, dt . \end{aligned}  }$$ 

Calling this error ${ \varepsilon (h, k) , }$ we have 

$${ \begin{aligned} &\, \lVert \varepsilon(h, k) \rVert \\ \leq &\, \max _{0 \leq s \leq 1} \lVert \partial _1 f (a + sh, b + k) - \partial _1 f(a, b)  \rVert \lVert h \rVert \\ &\, + \max _{0 \leq t \leq 1}  \lVert \partial _2 f (a, b+tk) - \partial _2 f (a, b) \rVert \lVert k \rVert  \\ \leq &\, \left( {\begin{aligned} &\, \max _{0 \leq s \leq 1} \lVert \partial _1 f (a + sh, b + k) - \partial _1 f(a, b)   \rVert \\ &\, + \max _{0 \leq t \leq 1} \lVert \partial _2 f (a, b+tk) - \partial _2 f (a, b)  \rVert  \end{aligned}} \right) \max \lbrace \lVert h \rVert , \lVert k \rVert \rbrace .  \end{aligned}  }$$ 

Now 

$${ (h, k) \mapsto \partial _1 f(a, b) \, h + \partial _2 f (a, b) \, k }$$ 

gives a continuous linear map ${ E \times F \to G , }$ and the error ${ \varepsilon(h, k) }$ satisfies ${ \varepsilon(0, 0) = 0 }$ and 

$${  \frac{\lVert \varepsilon(h, k) \rVert}{\max \lbrace \lVert h \rVert, \lVert k \rVert \rbrace}  \to 0 \quad \text{ as } \, \,  \max \lbrace \lVert h \rVert, \lVert k \rVert  \rbrace  \to 0 . }$$ 

Hence the ${ f }$ is differentiable at ${ (a, b) , }$ with 

$${ Df(a, b) \, (h, k) = \partial _1 f(a, b) \, h + \partial _2 f(a, b) \, k .   }$$ 

It is left to show that ${ f }$ is a ${ C ^p }$ map, that is ${ (x, y) \mapsto Df(x, y) }$ is ${ C ^{p-1} .  }$ The compositions 

$${ \underbrace{(x, y)} _{\in \, U \times V} \mapsto \underbrace{\partial _1 f(x, y)} _{\in \, L(E, G)} \mapsto \underbrace{(\partial _1 f (x, y), 0) } _{\in L(E, G) \times L(F, G)} }$$

$${ \underbrace{(x, y)} _{\in \, U \times V} \mapsto \underbrace{\partial _2 f(x, y)} _{\in \, L(F, G)} \mapsto \underbrace{(0, \partial _2 f (x, y)) } _{\in L(E, G) \times L(F, G)} }$$ 

are ${ C ^{p-1}, }$ hence their sum 

$${ \underbrace{(x, y)} _{\in \, U \times V} \mapsto \underbrace{(\partial _1 f (x, y), \partial _2 f (x, y))} _{\in \, L(E, G) \times L(F, G)} }$$ 

is ${ C ^{p-1} . }$ The map 

$${ \alpha : L(E, G) \times L(F, G) \longrightarrow L(E \times F, G), }$$

$${ \alpha (\varphi _1, \varphi _2) \, (h, k) = \varphi _1 (h) + \varphi _2 (k)   }$$ 

is continuous linear, hence the composition 

$${ \underbrace{(x, y)} _{\in \, U \times V} \mapsto \underbrace{(\partial _1 f (x, y), \partial _2 f (x , y))} _{\in \, L(E, G) \times L(F, G) }  \mapsto \underbrace{\alpha(\partial _1 f(x, y), \partial _2 f(x, y))} _{\in \, L(E \times F, G)}   }$$ 

is ${ C ^{p-1}, }$ as needed. ${ \blacksquare }$ 

Consider complete normed spaces ${ E, F, G , }$ and a ${ C ^p }$ map 

$${ f : U (\subseteq E \times F \text{ open}) \longrightarrow G . }$$ 

It has a zero set

$${  Z _f = \lbrace (x, y) : (x, y) \in U, f(x, y) = 0 \rbrace .  }$$ 

 Let ${ (a, b) \in Z _f . }$ The goal is to study the structure of ${ Z _f }$ near ${ (a, b) .}$    

 Informally, for small ${ \delta > 0 , }$ we have ${ B((a, b), \delta) \subseteq U }$ and 

 $${ \require{cancel} \begin{aligned} &\, Z _f \cap B((a, b), \delta) \\ = &\, \lbrace (a+h, b+k) : \lVert h \rVert < \delta, \lVert k \rVert < \delta, f(a+h, b+k) = 0  \rbrace \\ \approx &\, \lbrace (a+h, b+k) :  \lVert h \rVert < \delta, \lVert k \rVert < \delta,  \cancel{f(a, b)} + \partial _1 f (a, b) \, h + \partial _2 f (a, b) \, k = 0  \rbrace  \\ = &\, \lbrace (x, y) : \lVert x - a \rVert < \delta, \lVert y - b \rVert < \delta, \,  \partial _1 f (a, b) \, (x - a) + \partial _2 f (a, b) \, (y-b) = 0  \rbrace .  \end{aligned} }$$ 

 Now if ${ \partial _2 f(a, b) }$ is invertible, the approximating set looks like the graph of 

 $${ E \longrightarrow F , }$$ 
 
 $${ x \mapsto y = b - [\partial _2 f(a, b) ] ^{-1}  \partial _1 f (a, b) (x - a)   }$$ 

 within ${ B(a, \delta) \times B(b, \delta) . }$ This suggests the following. 

  
 **Thm** [Implicit function theorem]:    
 Consider complete normed spaces ${ E, F, G , }$ and a ${ C ^p }$ map 

$${ f : U (\subseteq E \times F \text{ open}) \longrightarrow G . }$$ 

It has a zero set

$${  Z _f = \lbrace (x, y) : (x, y) \in U, f(x, y) = 0 \rbrace .  }$$ 

 Let ${ (a, b) \in Z _f  }$ be such that ${ \partial _2 f(a, b) : F \to G }$ is a toplinear isomorphism.    
 Then there exist open neighbourhoods 

 $${ (a, b) \in \mathscr{U} \subseteq U, \quad a \in \mathscr{V} \subseteq E }$$ 

 and a ${ C ^p }$ map 

 $${ g : \mathscr{V} \longrightarrow F  }$$ 

 such that

 $${ Z _f  \cap \mathscr{U} = (\text{graph of } g)   }$$ 

 that is 

 $${ \lbrace (x, y) \in \mathscr{U} : f(x, y) = 0 \rbrace = \lbrace (x, g(x)) : x \in \mathscr{V}  \rbrace  .  }$$ 

 Further, 

 $${ Dg(x) = - [\partial _2 f \, (x, g(x))] ^{-1} \partial _1 f \, (x, g(x)) \quad \text{for all } x \in \mathscr{V} .   }$$ 

 $${ \boxed{\begin{aligned} &\, \textbf{Heuristic:}  \text{ If } f : U (\subseteq E \times F) \to G \text{ is a } C ^p \text{ map, } \\ &\, \text{near any point of } Z _f \text{ where } \partial _2 f \text{ is nonsingular, } Z _f \\ &\, \text{looks like the graph of a } C ^p \text{ map } V (\subseteq E) \to F .   \end{aligned} }  }$$ 


 **Pf**: Since ${ \partial _2 f (a, b) : F \to G }$ is a toplinear isomorphism, consider the map 

 $${ \hat{f} = [\partial _2 f (a, b) ] ^{-1} f : U (\subseteq E \times F ) \longrightarrow F .  }$$ 

 It is a ${ C ^p }$ map with ${ Z _{\hat{f}} = Z _f }$ and ${ \partial _2 \hat{f} (a, b) = \text{id} _F . }$    
 
 Rewriting the goal, we want open neighbourhoods 

 $${ (a, b) \in \mathscr{U} \subseteq U, \quad a \in \mathscr{V} \subseteq E  }$$ 

 and a ${ C ^p }$ map 

 $${ g : \mathscr{V} \longrightarrow F  }$$ 

 such that 

 $${ Z _{\hat{f}} \cap \mathscr{U} = (\text{graph of } g).    }$$ 

 $${ }$$ 

 In an attempt to “complete” the map 
 
 $${ \hat{f} : U (\subseteq E \times F) \longrightarrow F }$$ 
 
 to a map 
 
 $${ U (\subseteq E \times F) \longrightarrow E \times F }$$ 

 which is locally invertible at ${ (a, b) }$ i.e. has nonsingular derivative at ${ (a, b), }$ we can consider 

 $${ \varphi : U (\subseteq E \times F \text{ open}) \longrightarrow E \times F, }$$ 

 $${ \varphi (x, y) = (x, \hat{f}(x, y)) . }$$ 

 By a usual composition argument, it is a ${ C ^p }$ map. The derivative 

 $${ (D \varphi) (a, b) \in L(E \times F, E \times F) }$$ 

 is the derivative of the sum of ${ (x, y) \mapsto (x, 0) }$ and ${ (x, y) \mapsto (0, \hat{f}(x, y)) }$ at the point ${ (a, b), }$ and so is given by 

 $${ \begin{aligned} &\, (D \varphi) (a, b) \, (h, k) \\ = &\, (h, D \hat{f} (a, b) \, (h, k)  )  \\ = &\, (h,  \partial _1 \hat{f} (a, b) \, h + \partial _2 \hat{f} (a, b) \, k ) \\ = &\, (h, \partial _1 \hat{f}(a, b) \, h  + k )  \\ = &\, \begin{pmatrix} \text{id} _E &0 \\ \partial _1 \hat{f}(a, b) &\text{id} _F  \end{pmatrix} \begin{pmatrix} h \\ k \end{pmatrix}  \end{aligned}  }$$ 

 that is 

 $${ (D\varphi) (a, b) = \begin{pmatrix} \text{id} _E &0 \\ \partial _1 \hat{f}(a, b) &\text{id} _F  \end{pmatrix} \in L(E \times F, E \times F) .  }$$ 

 This continuous linear map has a continuous linear inverse 

 $${ \begin{pmatrix} \text{id} _E &0 \\ -\partial _1 \hat{f} (a, b) &\text{id} _F \end{pmatrix} \in L(E \times F, E \times F) ,   }$$ 

 hence ${ D\varphi (a, b) }$ is nonsingular as needed. 

 By inverse function theorem, ${ \varphi : U (\subseteq E \times F) \to E \times F }$ is a local ${ C ^p }$ isomorphism at ${ (a, b) . }$ There exist open neighbourhoods 

 $${ (a, b) \in W \subseteq U, \quad  (a, 0) \in W ^{’}   \subseteq E \times F }$$ 

 such that ${ \varphi \big\vert _{W } : W \longrightarrow W ^{’}$ is a ${ C ^p }$ isomorphism.    

 Let ${ \psi = \left(\varphi \big\vert _{W } \right) ^{-1}.   }$ It is of the form 

 $${ \psi (\mathbf{x}, \mathbf{y} ) = (\psi _1 (\mathbf{x}, \mathbf{y}), \psi _2 (\mathbf{x} , \mathbf{y}))   \quad \text{ for } (\mathbf{x}, \mathbf{y}) \in W ^{’}   }$$ 

 where ${ \psi _1 : W ^{’}  \to E  , }$ ${ \psi _2 : W ^{’}   \to F }$ are ${ C ^p }$ maps. It has a more specific structure. We have 

 $${ \begin{aligned} &\, (\mathbf{x}, \mathbf{y}) \\ = &\,  (\varphi \circ \psi)(\mathbf{x}, \mathbf{y}) \\ = &\, (\psi _1 (\mathbf{x}, \mathbf{y}),  \, \, \hat{f}(\psi _1 (\mathbf{x}, \mathbf{y}), \psi _2 (\mathbf{x}, \mathbf{y}))) \end{aligned}  }$$ 

that is 

 $${  \mathbf{x} = \psi _1 (\mathbf{x}, \mathbf{y}), \quad  \mathbf{y} = \hat{f}(\mathbf{x}, \psi _2 (\mathbf{x}, \mathbf{y}))    }$$ 

 for all ${ (\mathbf{x}, \mathbf{y}) \in W ^{’} . }$

 Especially 

 $${  (\mathbf{x}, 0) \in W ^{’} \implies   0 = \hat{f}(\underbrace{\mathbf{x},  \psi _2 (\mathbf{x}, 0)} _{= \,  \psi(\mathbf{x}, 0) \in W } ),   }$$ 

 that is points ${ (\mathbf{x}, 0) \in W ^{’} }$ give points ${ \psi (\mathbf{x}, 0) = (\mathbf{x}, \psi _2 (\mathbf{x}, 0)) \in Z _{\hat{f}} \cap W . }$ 
 
 Since 
 
 $${ \lbrace x \in E  : (x, 0) \in W ^{’} \rbrace  }$$
 
 is an open neighbourhood of ${ a, }$ this suggests that setting 

 $${ \mathscr{U} := W, \quad \mathscr{V} := \lbrace x \in E : (x, 0) \in W ^{’} \rbrace }$$ 

 and 

 $${ g : \mathscr{V} \longrightarrow  F, \quad g(x) = \psi _2 (x, 0)   }$$ 

 works. 

Indeed, the graph of ${ g }$ looks like 

$${ \begin{aligned} &\, (\text{graph of } g) \\ = &\, \lbrace (x, \psi _2 (x, 0)) : (x, 0) \in W ^{’} \rbrace \\ \subseteq &\, Z _{\hat{f}} \, \cap W  ,   \end{aligned} }$$ 

and it is left to show that every point of ${ Z _{\hat{f}} \cap W }$ lies is in the graph of ${ g . }$ 

We have 

$${ \begin{aligned} &\, (x, y) \\ = &\, (\psi \circ \varphi)(x, y) \\ = &\, (x, \,  \psi _2 (x, \hat{f}(x, y)) \end{aligned}  }$$

for all ${ (x, y) \in W ,  }$ that is 

$${ y = \psi _2 (x, \hat{f}(x, y))  \quad \text{ for all } (x, y) \in W . }$$

Especially 

$${ y = \psi _2 (x, 0) \quad \text{ for all } (x, y) \in Z _{\hat{f}} \cap W .  }$$ 

Finally 

$${ \begin{aligned} &\, (x, y) \in Z _{\hat{f}} \cap W \\ \implies &\, y = \psi _2 (x, 0), \, \,  \underbrace{\varphi(x, y)} _{ (x, 0)} \in W ^{’}  \end{aligned}  }$$ 

that is 

$${ Z _{\hat{f}} \cap W \subseteq (\text{graph of } g) ,  }$$ 

as needed. The second part on derivative of the implicit function ${ g  }$ will be proved below. ${ \blacksquare }$


