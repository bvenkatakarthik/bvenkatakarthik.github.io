---
layout: post
title: "Cryptography"
author: "Karthik"
categories: journal
tags: [documentation,sample]
---

[Link to lectures](https://www.coursera.org/learn/cryptography) 

Instructor: Prof. Jonathan Katz   

Book: “Introduction to Modern Cryptography” by Katz and Lindell

**ROUGH NOTES (!)**
Updated: 14/2/24 

**Week-1**: 

Classical Cryptography focuses exclusively on ensuring secret communication between ${ 2 }$ parties sharing secret information in advance (That is, the focus is on private-key encryption schemes).  

Private-key encryption schemes enable ${ 2 }$ parties who shared some secret information in advance to communicate over a public channel, while keeping the contents of their communication private from any adversarial eavesdropper. 

Modern Cryptography has a broader scope, dealing with: 
* Ensuring data privacy (as in Classical Cryptography) 
* Ensuring data integrity (i.e. ensuring data is not modified improperly), user authentication
* Public-key encryption (where communicating users do not share any secret information in advance) 
* Foundational topics like Number Theory and Information Theory 
* Systems like electronic voting, distributed e-cash, etc. 

Modern Cryptography deals with design, analysis, implementation of techniques for securing information, systems and computation (all very general terms) against adversarial attack. 

**Eg**: ([Lecture](https://youtu.be/VDSznMMOaHE?si=bK3AoEVEtYrOV8lv) at 17:00) Consider a framework for a doctor to digitally access and change medical records.   

Ideally: Doctor (digitally) asks for a patient Alice’s record. Hospital (digitally) sends Alice’s record ${ R _A .}$ Doctor asks to update Alice’s record to ${ S _A .}$ Hospital updates the record.  

Some security concerns in this example are:   
* [Authenticity and Integrity] From Doctor point of view: Was ${ R _A }$ really sent by the hospital ? Even if so, was it modified en route ? From Hospital point of view: Is the retrieve request really from Alice’s doctor ? Is the store request really from Alice’s doctor ? Even if so, was ${ S _A }$ modified en route ?   
* [Privacy] Eavesdroppers shouldn’t get Alice’s record. 

Some uses of Cryptography:  
* Passwords, password hashing (Secure login passwords from being eavesdropped) 
* Secure credit-card transactions over the web  
* Encrypted WiFi 
* Disk encryption 
* Digitally signed software updates 
* Bitcoin 

Threat modelling and proofs of security form the modern crypto mindset. 

Two important cryptographic goals are secrecy and integrity.   
In the private-key setting, secrecy is ensured by private-key encryption and integrity is ensured by message authentication codes.   
In the public-key setting, secrecy is ensured by public-key encryption and integrity is ensured by digital signatures.  

Building blocks: 
* Pseudorandom number generators and Pseudorandom functions 
* Block ciphers 
* Hash functions 
* Number theory 

As mentioned, a private-key/symmetric-key encryption scheme relies on secret information (a key) shared between the communicating parties. Say we have Alice and Bob communicating in a private-key setting. It typically works like:  
* Alice and Bob share a secret key ${ k }$ in advance. 
* When Bob has a message/plaintext for Alice, he encrypts the message using the shared key (and an encryption algorithm). This generates a ciphertext which he sends to Alice over a public communication channel. 
* Alice can then decrypt the ciphertext using the shared key (and a decryption algorithm) to recover the original message. 

We aim for a security guarantee that no eavesdropper who observes the ciphertext sent can figure out anything about the underlying message. 

**Def**: Formally, a **private-key encryption scheme** is defined by a **message space** ${ \mathcal{M} }$ (of messages supported by the scheme) along with algorithms ${ (\texttt{Gen, Enc, Dec}) }$ where:   
* ${ \texttt{Gen} }$ (**key generation algorithm**): Randomized algorithm, generates ${ k }$ 
* ${ \texttt{Enc} }$ (**encryption algorithm**): Takes a key ${ k }$ and message ${ m \in \mathcal{M} }$ as input, outputs ciphertext ${ c .}$ We write ${ c \leftarrow \texttt{Enc} _k (m)  }.$ 
> Left arrow is used to denote assignment of output when an algorithm is randomized. 
* ${ \texttt{Dec} }$ (**decryption algorithm**): Takes a key ${ k }$ and ciphertext ${ c }$ as input, outputs ${ m  }$ or  “error”. We write ${ m := \texttt{Dec} _k (c) .}$ 

We also have a **correctness condition**: For all ${ m \in \mathcal{M} }$ and all ${ k }$ output by ${ \texttt{Gen} ,}$ we must have $${ \texttt{Dec} _k (\texttt{Enc} _k (m)) = m .}$$ 

**Eg**: Consider the shift cipher (useless, just to illustrate the definition):   
* Message space consists of strings of english letters (with punctuation removed and no distinction between upper and lower case). On equating the english alphabet with the set ${ \lbrace 0, 1, \ldots, 25 \rbrace }$ (so for eg ${ \texttt{a} = 0, \texttt{b} = 1, }$ etc.) the message space ${ \mathcal{M} }$ consists of all finite sequences of numbers from this set.
* Algorithm ${ \texttt{Gen} }$ outputs a uniform key ${ k \in \lbrace 0, 1, \ldots, 25 \rbrace .}$ 
* Encryption of a message ${ m = m _1 \ldots m _{\ell} }$ (each ${ m _i \in \lbrace 0, 1, \ldots, 25 \rbrace }$) using key ${ k }$ is $${ \texttt{Enc} _k (m) = c _1 \ldots c _{\ell} \text{ where } c _i = [(m _i + k) \, \text{mod } 26]. }$$ 
* Decryption of a ciphertext ${ c = c _1 \ldots c _{\ell} }$ using key ${ k }$ is $${ \texttt{Dec} _k (c) = m _1 \ldots m _{\ell} \text{ where } m _i = [(c _i - k) \, \text{mod } 26]. }$$ 

The shift cipher is not secure, there are only ${ 26 }$ possible keys. Given a ciphertext, an attacker (who knows everything about the scheme except the key) can simply try decrypting using every possible key (and of the ${ 26 }$ candidate plaintexts, typically one which “makes sense” is the actual plaintext). 

Kerckhoff’s principle is that an encryption scheme used is not to be considered secret, but the only secret information is the key shared by the parties.   
Some reasons are:   
* It is easier to maintain secrecy of a short key rather than a more complex algorithm. 
* It is important that encryption schemes receive public scrutiny before widespread deployment. So encryption schemes should be public. 

The key space ${ \mathcal{K} }$ of an encryption scheme is the set of all keys that can be output by the key generation algorithm. For an encryption scheme to be secure, it must have a key space large enough to prevent an exhaustive search attack like in the shift cipher (although a large key space alone doesn’t guarantee security).

**Eg**: Consider the Vigenère cipher. The key is now a string. To encrypt, put the key above the message (repeat the key as needed), and shift each character by the amount dictated by the adjacent character of the key. Decryption is the reverse process.   
Key space of this cipher very large. For eg if keys are ${ 14 }$ character strings, then key space has size ${ 26 ^{14} \, (\geq (2 ^4) ^{14} = 2 ^{56}). }$ Exhaustive search attack is infeasible, but it is vulnerable to frequency analysis. (For simplicity, assume the attacker knows the key length is ${ 14 .}$ Now every ${ 14 }$th character in the ciphertext has been shifted by the same amount. Comparing letter frequencies in this substring and in generic english texts, we get candidates for the shifting character, namely ${ 0 }$th character of the key. One can continue so.)   
This attack will only work given a long enough ciphertext. Also better attacks are known. In any case, the Vigenere cipher is not very secure despite having a large key space. 

Modern cryptography differs from classical cryptography in that the emphasis is on threat models and proofs of security.   
With a few exceptions, cryptography currently relies on some (unproved) complexity assumptions, on the impossibility of solving certain problems efficiently. 

Some threat models in a private-key encryption scheme are (in increasing order of strength):   
* Ciphertext-only attack (Here the attacker only gets to observe ciphertext(s) sent by the parties and nothing else) 
* Known-plaintext attack (Here in addition to above the attacker is able to learn one or more plaintext-ciphertext pairs generated using the same key) 
> Attacker’s goal then is to deduce information about the underlying plaintext of some other ciphertext, produced using the same key. 
* Chosen-plaintext attack (Here in addition to above the attacker can obtain plaintext-ciphertext pairs for plaintexts of its choice) 
* Chosen-ciphertext attack (Here in addition to above the attacker can obtain decryptions of ciphertexts of its choice) 

For now consider the simplest threat model, an eavesdropper making a ciphertext-only attack. How should we define security?   
One informal definition is: An encryption scheme is secure if, regardless of any prior info the attacker has of the plaintext, the ciphertext can leak no additional info about the plaintext.   

Consider an encryption scheme ${ (\texttt{Gen, Enc, Dec}),}$ with message space ${ \mathcal{M} .}$ Consider the randomized experiment:  

* Choose a message ${ m \in \mathcal{M} }$ according to some distribution
* Generate a key ${ k }$ using ${ \texttt{Gen} }$ 
* Compute ${ c \leftarrow \texttt{Enc} _k (m) .}$ 

This defines a distribution on the ciphertext. Let ${ C }$ be the random variable denoting the value of the ciphertext in this experiment.   

**Def**: Encryption scheme ${ (\texttt{Gen, Enc, Dec}) }$ with message space ${ \mathcal{M} }$ and ciphertext space ${ \mathcal{C} }$ is **perfectly secret** if for every prior distribution over ${ \mathcal{M} ,}$ every ${ m \in \mathcal{M}, }$ and every ${ c \in \mathcal{C} }$ with ${ \mathbb{P}(C = c) > 0 ,}$ we have $${ \mathbb{P}[M = m \, \vert \, C = c] = \mathbb{P}[M = m] .}$$

**Eg**: The one time pad is an encryption scheme with perfect secrecy (although less practical due to requiring long keys). In the scheme: 

* ${ \mathcal{M} = \lbrace 0, 1 \rbrace ^n }$
* ${ \texttt{Gen} }$: choose a uniform key ${ k \in \lbrace 0, 1 \rbrace ^n }$ 
* ${ \texttt{Enc} }$: ${ \texttt{Enc} _k (m) = k \oplus m }$ (bit-wise XOR) 
* ${ \texttt{Dec} }$: ${ \texttt{Dec} _k (c) = k \oplus c .}$

**Thm**: One time pad is perfectly secret.    
**Sketch**: Fix an arbitrary distribution over ${ \mathcal{M} = \lbrace 0, 1 \rbrace ^n ,}$ and arbitrary ${ m, c \in \lbrace 0, 1 \rbrace ^n .}$   
Now 

$${ \begin{align*} \mathbb{P}[M = m \, \vert \, C = c] &= \mathbb{P}[C = c \, \vert \, M = m] \frac{\mathbb{P}[M=m]}{\mathbb{P}[C=c]}  \end{align*} }$$ 

with terms 

$${ \begin{align*} \mathbb{P}[C = c \, \vert \, M = m ] &= \mathbb{P}[K = c \oplus m \, \vert \, M = m ] \\ &= \mathbb{P}[K = c \oplus m] \\ &= 2 ^{-n} \end{align*} }$$ 

and

$${ \begin{align*} \mathbb{P}[C = c] &= \sum _{m ^{'}} \mathbb{P}[C = c \, \vert \, M = m ^{'}] \,  \mathbb{P}[M = m ^{'}] \\ &= \sum _{m ^{'}} 2 ^{-n}  \,  \mathbb{P}[M = m ^{'}] \\ &= 2 ^{-n} .\end{align*} }$$ 

Hence 

$${ \mathbb{P}[M = m \, \vert \, C = c] = \mathbb{P}[M = m] }$$ 

as needed.  

Random number generation: 

When describing algorithms, we often assume access to uniform random bits. Where do these actually come from?   

One way computers do it is:  

* Continually collect a pool of high-entropy (roughly, “unpredictable”) data. 
* When random bits are needed, process this data to generate independent, uniform sequence of bits.

For the pool of high-entropy data, it can come from:

* External inputs (Delays between network events, Hard-disk access times, etc) 
* Hardware random-number generation (eg some [Intel chips](https://en.m.wikipedia.org/wiki/RDRAND))

Limitations of one time pad: 

* The key (to be shared apriori) is as long as the message. 
* Only secure if each key is used to encrypt a single message (if two messages ${ m _1, m _2 }$ are encrypted using same key ${ k ,}$ then the adversary can XOR the ciphertexts to get ${ (m _1 \oplus k) \oplus (m _2 \oplus k) }$ ${ = m _1 \oplus m _2 ,}$ which leaks info about ${ m _1 }$ and ${ m _2 }$). 

**Thm**: If an encryption scheme ${ (\texttt{Gen, Enc, Dec}) }$ with message space ${ \mathcal{M} }$ is perfectly secret, then key space is atleast as large as the message space, that is ${ \vert \mathcal{K} \vert \geq \vert \mathcal{M} \vert .}$   

> So if ${ \mathcal{M} = \lbrace 0, 1 \rbrace ^m }$ and ${ \mathcal{K} = \lbrace 0, 1 \rbrace ^n, }$ we must have ${ n \geq m }$ i.e. keys are atleast as long as the messages. 

**Sketch**: Suppose ${ \vert \mathcal{K} \vert < \vert \mathcal{M} \vert .}$ Pick the uniform distribution over ${ \mathcal{M} , }$ and let ${ c \in \mathcal{C} }$ be a ciphertext which occurs with nonzero probability. Let ${ \mathcal{M}(c) }$ be the set of all decryptions of ${ c ,}$ that is 

$${ \mathcal{M}(c) := \lbrace \texttt{Dec} _k (c) \, \vert \, k \in \mathcal{K} \rbrace .   }$$ 

Since ${ \texttt{Dec} }$ is deterministic, ${ \vert \mathcal{M}(c) \vert \leq \vert \mathcal{K} \vert .}$ Since ${ \vert \mathcal{K} \vert < \vert \mathcal{M} \vert ,}$ there is a message ${ m ^{'} \in \mathcal{M} }$ with ${ m ^{'} \notin \mathcal{M}(c) .}$ But now 

$${ \mathbb{P}[M = m ^{'} \, \vert \, C = c ] = 0 \neq \mathbb{P}[M = m ^{'}]  }$$

so the scheme is not perfectly secret, a contradiction. 

**Def**: Let ${ \Pi = (\texttt{Gen, Enc, Dec}) }$ be an encryption scheme with message space ${ \mathcal{M} .}$ Let ${ \mathcal{A} }$ be an adversary (eavesdropper). We define an experiment ${ \texttt{PrivK} ^{\text{eav}} _{\mathcal{A}, \Pi} }$ as follows: 

Adversarial indistinguishability experiment ${ \texttt{PrivK} ^{\text{eav}} _{\mathcal{A}, \Pi} }$:   

* Adversary ${ \mathcal{A} }$ outputs a pair of messages ${ m _0, m _1 \in \mathcal{M} .}$ 
* A key ${ k }$ is generated using ${ \texttt{Gen} ,}$ and a uniform bit ${ b \in \lbrace 0, 1 \rbrace }$ is chosen. Ciphertext ${ c \leftarrow \texttt{Enc} _k (m _b) }$ is computed and given to ${ \mathcal{A} .}$ 
> We call ${ c }$ the challenge ciphertext. 
* ${ \mathcal{A} }$ outputs a bit ${ b ^{'} . }$ 
* Output of the experiment is ${ 1 }$ (and we write ${ \texttt{PrivK} ^{\text{eav}} _{\mathcal{A}, \Pi} = 1 }$) if ${ b ^{'} = b ,}$ and output is ${ 0 }$ otherwise. 

**Def**: Encryption scheme ${ \Pi = (\texttt{Gen, Enc, Dec}) }$ with message space ${ \mathcal{M} }$ is **perfectly indistinguishable** if for every adversary ${ \mathcal{A} }$ we have 

$${ \mathbb{P}\left[ \texttt{PrivK} ^{\text{eav}} _{\mathcal{A}, \Pi} = 1 \right] = \frac{1}{2}.  }$$ 

**Thm**: An encryption scheme is perfectly secret if and only if it is perfectly indistinguishable. 
**Sketch**: (To Do) 

**Week-2**: 

We can relax the definition of perfect indistinguishability to get the definition of computational secrecy.   
There are two approaches for the relaxation: Concrete and Asymptotic. 

Computational indistinguishability (concrete approach):   
**Def**: Encryption scheme ${ \Pi }$ is ${ (t, \varepsilon)-}$indistinguishable if for all attackers ${ \mathcal{A} }$ running in time atmost ${ t }$ (time is measured in CPU cycles ?) it holds that $${ \mathbb{P}\left[ \texttt{PrivK} _{\mathcal{A}, \Pi} = 1 \right] \leq \frac{1}{2} + \varepsilon .}$$   
Concrete security approach is sensitive to the exact computational model, and doesn’t lead to a nice theory. 

We now focus on the asymptotic approach. Here we introduce a **security parameter** ${ n \in \mathbb{Z} _{>0} }$ (usually the key length) which is: 

* Fixed by honest parties at initialization. It allows users to tailor the security level. 
* Known by the adversary. 

We now view running times of all parties, and success probability of the adversary, as functions of ${ n .}$ 

Computational indistinguishability (asymptotic approach): The informal idea is 

* Security may fail with probability **negligible** in ${ n }.$ 
* Restrict attention to attacks running in time **polynomial** (in the sense polynomially bounded) in ${ n }.$ 

Recall a function ${ f : \mathbb{Z} _{> 0} \to \mathbb{R} _{\geq 0} }$ is **polynomially bounded** if there is a constant ${ c }$ such that ${ f(n) < n ^c }$ for all ${ n .}$ An algorithm ${ \mathcal{A} }$ **runs in polynomial time** if there is a polynomial ${ p }$ such that, for every input ${ x \in \lbrace 0, 1 \rbrace ^{\*}, }$ the computation of ${ \mathcal{A}(x) }$ terminates within atmost ${ p(\vert x \vert) }$ steps. (What exactly is a step? What exactly is a Probabilistic Polynomial Time Algorithm? Should look at Theory of Computation)

A function ${ f : \mathbb{Z} _{> 0} \to \mathbb{R} _{\geq 0} }$ is **negligible** if for every polynomial ${ p }$ (with positive leading coefficient) there is an ${ N }$ such that ${ f(n) < \frac{1}{p(n)} }$ whenever ${ n > N .}$ A typical example is ${ f(n) = P(n) 2 ^{-cn} }$ for polynomial ${ P }.$ 

We can redefine encryption schemes and secure encryption, introducing a security parameter and runtime constraints. 

**(Re)Def**: A **private-key encryption scheme** is defined by ${ 3 }$ PPT (Probabilistic Polynomial Time) algorithms ${ (\texttt{Gen, Enc, Dec}) }$ such that: 

* ${ \texttt{Gen} }$ (key generation algorithm): Takes as input ${ 1 ^n }$ and outputs a key ${ k }$ with ${ \vert k \vert \geq n }.$ We write ${ k \leftarrow \texttt{Gen}(1 ^n) .}$ 
* ${ \texttt{Enc} }$ (encryption algorithm): Takes as input a key ${ k }$ and message ${ m \in \lbrace 0, 1 \rbrace ^{\*} .}$ Outputs a ciphertext ${ c .}$ We write ${ c \leftarrow \texttt{Enc} _{k} (m) .}$ 
* ${ \texttt{Dec} }$ (decryption algorithm): Takes as input a key ${ k }$ and ciphertext ${ c.}$ Outputs a message ${ m \in \lbrace 0, 1 \rbrace ^{\*} }$ or error ${ \perp .}$ 
* Correctness condition: For every ${ n,}$ for every key ${ k }$ output by ${ \texttt{Gen}(1 ^n) ,}$ and every ${ m \in \lbrace 0, 1 \rbrace ^{\*} ,}$ we must have ${ \texttt{Dec} _k (\texttt{Enc} _k (m)) = m .}$

> If ${ (\texttt{Gen, Enc, Dec}) }$ above is such that for ${ k }$ output by ${ \texttt{Gen}(1 ^n) }$ the algorithm ${ \texttt{Enc} _k }$ is defined only for messages ${ m \in \lbrace 0, 1 \rbrace ^{\ell (n)} ,}$ we say ${ (\texttt{Gen, Enc, Dec}) }$ is a fixed-length private-key encryption scheme for messages of length ${ \ell(n) .}$ 

**Def**: As before, we can define the adversarial indistinguishability experiment ${ \texttt{PrivK} ^{\text{eav}} _{\mathcal{A}, \Pi} (n) }$:   

* The adversary ${ \mathcal{A} }$ is given input ${ 1 ^n },$ and outputs a pair of messages ${ m _0, m _1 }$ with ${ \vert m _0 \vert = \vert m _1 \vert .}$ 
* A uniform bit ${ b \in \lbrace 0, 1 \rbrace }$ is chosen. A key is generated using ${ \texttt{Gen}(1 ^n) }$ and ciphertext ${ c \leftarrow \texttt{Enc} _k (m _b) }$ is computed and given to ${ \mathcal{A} .}$ 
> We call ${ c }$ the challenge ciphertext. 
* ${ \mathcal{A} }$ outputs a bit ${ b ^{'} \in \lbrace 0, 1 \rbrace .}$ 
* The output of the experiment is ${ 1 }$ (written ${ \texttt{PrivK} ^{\text{eav}} _{\mathcal{A}, \Pi} (n) = 1 }$) if ${ b = b ^{'} }$ and ${ 0 }$ otherwise. 

**Def**: An encryption scheme ${ \Pi }$ is computationally indistinguishable if for all PPT attackers ${ \mathcal{A} }$ there is a negligible function ${ \varepsilon (n) }$ such that 

$${ \mathbb{P}\left[ \texttt{PrivK} _{\mathcal{A}, \Pi} (n) = 1 \right]  \leq \frac{1}{2} + \varepsilon(n).  }$$ 

Pseudorandomness is an important building block for building computationally secure schemes. Like with computational security, there are two approaches to defining it, concrete and asymptotic. 

Pseudorandomness (concrete approach):   
**Def**: Let ${ D }$ be a probability distribution on ${ n -}$bit strings ${ \lbrace 0, 1 \rbrace ^n .}$ (Recall ${ x \leftarrow D }$ means ${ x }$ is sampled according to ${ D }$). We say ${ D }$ is ${ (t, \varepsilon) -}$pseudorandom if for all statistical tests ${ \mathcal{A} }$ running in time ${ \leq t }$ (Todo: check how time is talked about, without being hardware/implementation specific, in theory of computation) we have 

$${ \vert \mathbb{P} _{x \leftarrow D} [\mathcal{A}(x) = 1] - \mathbb{P} _{x \leftarrow U _n} [\mathcal{A}(x)=1] \vert \leq \varepsilon }$$

where ${ U _n = \text{Unif}\lbrace 0, 1 \rbrace ^n.}$ 

Pseudorandomness (asymptotic approach):   
**Def**: Consider a security parameter ${ n ,}$ and a polynomial ${ p(n) }$ (giving lengths of strings, as below). Consider a sequence of probability distributions ${ (D _n) }$ where each ${ D _n }$ is a distribution on ${ \lbrace 0, 1 \rbrace ^{p(n)} .}$ This sequence of distributions is **pseudorandom** if for every PPT attacker ${ \mathcal{A} }$ there is a negligible function ${ \varepsilon }$ such that 

$${ \vert \mathbb{P} _{s \leftarrow D _n} [\mathcal{A}(s) = 1] - \mathbb{P} _{s \leftarrow U _{p(n)}} [\mathcal{A}(s) = 1] \vert \leq \varepsilon (n)  }$$ 

where ${ U _{p(n)} = \text{Unif}\lbrace 0, 1 \rbrace ^{p(n)} .}$ 

A pseudorandom generator PRG is an efficient deterministic algorithm that expands a short uniform seed to a longer pseudorandom output. 

**Def**: Let ${ G }$ be a deterministic poly-time algorithm, such that for any ${ n }$ and any input ${ s \in \lbrace 0, 1 \rbrace ^{n} }$ the result ${ G(s) \in \lbrace 0, 1 \rbrace ^{p (n)}  }$ (and ${ p }$ is a polynomial). We call ${ G }$ a **pseudorandom generator** if:   
* ${ p(n) > n }$ for every ${ n .}$ 
* For any PPT algorithm ${ \mathcal{A} ,}$ there is a negligible function ${ \varepsilon (n) }$ such that $${ \vert \mathbb{P} _{s \leftarrow U _n} [\mathcal{A}(G(s)) = 1] - \mathbb{P} _{s \leftarrow U _{p(n)} } [\mathcal{A}(s) = 1] \vert  \leq \varepsilon(n). }$$ That is, the sequence of distributions ${ D _n }$ given by the random vectors ${ \lbrace G(s) : s \leftarrow U _n \rbrace }$ is pseudorandom. 

An unconditional proof that PRGs exist is not yet known. But there are practical examples of PRGs. 

**Def**: Let ${ G }$ be a deterministic poly-time algorithm, with ${ \vert G(s) \vert = p(\vert s \vert) > \vert s \vert.  }$ Let ${ n }$ be a security parameter. A **pseudo one time pad** encryption scheme works as follows: 

* ${ \texttt{Gen} }$: on input ${ 1 ^n ,}$ output uniform ${ n-}$bit key ${ k .}$
* ${ \texttt{Enc} }$: given a key ${ k \in \lbrace 0, 1 \rbrace ^n }$ and message ${ m \in \lbrace 0, 1 \rbrace ^{p(n)} }$ output ${ c = G(k) \oplus m .}$ 
* ${ \texttt{Dec} }$: given a key ${ k \in \lbrace 0, 1 \rbrace ^n  }$ and ciphertext ${ c \in \lbrace 0, 1 \rbrace ^{p(n)} }$ output ${ m = G(k) \oplus c .}$ 

Correctness condition clearly holds. If ${ G }$ is a PRG, we also have computational security. 

**Thm**: If ${ G }$ is a PRG, the above pseudo one time pad is computationally secure.   

**Sketch**: (Proof by Reduction)   
Let ${ G }$ be a PRG with expansion factor ${ p(n), }$ and let ${ \Pi }$ be the above pseudo OTP encryption scheme. We are to show that ${ \Pi }$ is computationally secure, that is for any PPT attacker ${ \mathcal{A} }$ there is a negligible function ${ \varepsilon(n) }$ such that ${ \mathbb{P}\left[ \texttt{PrivK} _{\mathcal{A}, \Pi} (n) = 1 \right] \leq \frac{1}{2} + \varepsilon(n). }$   

Fix an ${ n }$. Let ${ \mathcal{A} }$ be a PPT attacker. We construct a distinguisher ${ D }$ that takes a string ${ w \in \lbrace 0, 1 \rbrace ^{p(n)} }$ as input and whose goal is to determine whether ${ w }$ was chosen uniformly or was a pseudorandom output from ${ G .}$ We can define ${ D }$ to be: 

Distinguisher ${ D }$: 
${ D }$ is given an input string ${ w \in \lbrace 0, 1 \rbrace ^{p(n)} }.$ 
* Run ${ \mathcal{A}(1 ^n) }$ to obtain pair of messages ${ m _0, m _1 \in \lbrace 0, 1 \rbrace ^{p(n)} .}$ 
* Choose a uniform bit ${ b \in \lbrace 0, 1 \rbrace .}$ Set ${ c = w \oplus m _b .}$ 
* Give ${ c }$ to ${ \mathcal{A} }$ and obtain output ${ b ^{'} .}$ Output ${ 1 }$ if ${ b = b ^{'} }$ and ${ 0 }$ otherwise. 

We see ${ D }$ runs in polynomial time. In contrast to above pseudo OTP ${ \Pi ,}$ consider the classical OTP ${ \tilde{\Pi} }$ which generates and uses a uniform key ${ k \in \lbrace 0, 1 \rbrace ^{p(n)} .}$ Now: 

* Perfect secrecy of OTP ${ \tilde{\Pi} }$ gives ${ \mathbb{P}\left[\texttt{PrivK} _{\mathcal{A}, \tilde{\Pi}} (n) = 1 \right] = \frac{1}{2}. }$ 
* **If input to D is ${ w \leftarrow U _{p(n)} }$**: The view of ${ \mathcal{A} }$ when run as a subroutine by ${ D }$ is identical to the view of ${ \mathcal{A} }$ in classical OTP experiment ${ \texttt{PrivK} _{\mathcal{A}, \tilde{\Pi}} (n) .}$ So $${ \begin{align*} \mathbb{P} _{w \leftarrow U _{p(n)}} [D(w) = 1] &= \mathbb{P} _{w \leftarrow U _{p(n)}} [b ^{'} = b] \\ &= \mathbb{P}\left[ \texttt{PrivK} _{\mathcal{A}, \tilde{\Pi}} (n) = 1 \right] \\ &= \frac{1}{2}.  \end{align*} }$$ 
* **If input to D is ${ w = G(k) }$ where ${ k \leftarrow U _n }$**: The view of ${ \mathcal{A} }$ when run as a subroutine by ${ D }$ is identical to the view of ${ \mathcal{A} }$ in pseudo OTP experiment ${ \texttt{PrivK} _{\mathcal{A}, \Pi} (n) .}$ So $${ \begin{align*} \mathbb{P} _{k \leftarrow U _n} [D(G(k)) = 1] &= \mathbb{P}\left[ \texttt{PrivK} _{\mathcal{A}, \Pi}  (n) = 1 \right].  \end{align*}  }$$
* By pseudorandomness of the (sequence of) distributions of ${ \lbrace G(k) : k \leftarrow U _n \rbrace ,}$ we have $${ \left\vert \mathbb{P} _{k \leftarrow U _n} [D(G(k)) = 1] - \mathbb{P} _{w \leftarrow U _{p(n)}} [D(w) = 1 ]  \right\vert \leq \varepsilon (n)  }$$ for a negligible function ${ \varepsilon (n) .}$ 

Substituting in the pseudorandomness condition the above values, we get 

$${ \left\vert \mathbb{P}\left[ \texttt{PrivK} _{\mathcal{A}, \Pi}  (n) = 1 \right] - \frac{1}{2} \right\vert \leq \varepsilon(n) .}$$

So especially ${ \mathbb{P}\left[ \texttt{PrivK} _{\mathcal{A}, \Pi}  (n) = 1 \right] \leq \frac{1}{2} + \varepsilon(n)  ,}$ as needed. 

**Week-3**: 

(Todo: PRFs, Block Ciphers, CPA and CCA security, etc.)
