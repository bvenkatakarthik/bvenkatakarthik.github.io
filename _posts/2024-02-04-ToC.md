---
layout: post 
title: "Theory of Computation"
author: "Karthik"
categories: journal 
tags: [documentation,sample]
---

[Link to Lectures](https://youtube.com/playlist?list=PLUl4u3cNGP60_JNv2MmK3wkOt9syvfQWY&si=QalkEiI6vK5-BaGl) 

Instructor: Prof. Michael Sipser 

Book: “Introduction to the Theory of Computation” by Michael Sipser 

**ROUGH NOTES (!)**   

**Lec-1**: 

Computability Theory (1930s - 50s): What is computable or not ?   
* Eg: Program verification, Pure mathematical truth   
* Models of computation: Finite automata, Turing machines

Complexity Theory (1960s - Present): What is computable in practice ? 
* Eg: Factoring problem, in fact P vs NP problem 
* Measures of complexity: Time and Space

> P vs NP is a [millennium prize problem](https://www.claymath.org/wp-content/uploads/2022/06/pvsnp.pdf). [Geometric Complexity Theory](https://en.m.wikipedia.org/wiki/Geometric_complexity_theory) is a research program aimed at resolving this is.

A **finite automaton** is a ${ 5 - }$tuple ${ (Q, \Sigma, \delta, q _0, F) }$ where: 
* ${ Q }$ is a finite set of states 
* ${ \Sigma }$ is a finite set of alphabet symbols 
* ${ \delta }$ is a transition function ${ \delta : Q \times \Sigma \to Q }$ 
* ${ q _0 \in Q }$ is the start state 
* ${ F \subseteq Q }$ is the set of final/accept states. 

A **string** is a finite sequence of symbols in ${ \Sigma }.$ A **language** is a (finite or infinite) set of strings.   
The empty string ${ \varepsilon }$ is the string of length ${ 0 .}$ The empty language ${ \emptyset }$ is the language with no strings. 

Finite automaton ${ M }$ **accepts string** ${ w = w _1 \ldots w _n }$ (each ${ w _i \in \Sigma }$) if there is a sequence of states ${ r _0, r _1, \ldots, r _n \in Q }$ such that: 
* ${ r _0 = q _0 }$ 
* ${ r _i = \delta (r _{i-1}, w _i) }$ for ${ 1 \leq i \leq n }$ 
* ${ r _n \in F .}$ 

For a finite automaton ${ M ,}$ the language ${ L(M) = \lbrace w \vert M \text{ accepts } w \rbrace }$ is called the **language of** ${ M .}$ (We also say ${ M }$ recognizes ${ L(M) }$).   
A language is called **regular** if some finite automaton recognizes it. 

Goal: Understand the regular languages. 

Eg: The language ${ \lbrace w \in \lbrace 0,1 \rbrace ^{*} \vert w \text{ contains substring } 11 \rbrace }$ is regular. (Language of the automaton [here](https://youtu.be/9syvZr-9xwk?si=nYAXozKXuL9QQMiu) at 30:00).   
The language ${ \lbrace w \vert w \text{ has equal number of } 0s \text{ and } 1s \rbrace }$ is not regular (will show later). 

Operations on languages:   
Let ${ A, B }$ be languages. Then we have languages:   
* **Union** ${ A \cup B }$ ${ = \lbrace w \vert w \in A \text{ or } w \in B \rbrace }$
* **Concatenation** ${ AB }$ ${ = \lbrace xy \vert x \in A \text{ and } y \in B \rbrace }$ 
* **Star** ${ A ^{\*} }$ ${ = \lbrace x _1 \ldots x _{k} \vert \text{each } x _i \in A \text{ for } k \geq 0 \rbrace }$ (Note empty string ${ \varepsilon \in A ^{\*} }$ always). 

We say ${ R }$ is a **regular expression** if ${ R }$ is: 
* ${ a }$ for some ${ a \in \Sigma }$ 
* ${ \varepsilon }$ 
* ${ \emptyset }$ 
* ${ R _1 \cup R _2 }$ where ${ R _1, R _2 }$ are regular expressions 
* ${ (R _1 \circ R _2) }$ where ${ R _1, R _2 }$ are regular expressions 
* ${ R _1 ^{*} }$ where ${ R _1 }$ is a regular expression.

Informally, regular expressions are built from elements of ${ \Sigma ,}$ empty string ${ \varepsilon ,}$ empty set ${ \emptyset ,}$ and finite union, concatenation, star operations.

Eg: Say ${ \Sigma = \lbrace 0, 1 \rbrace. }$ Expression ${ (0 \cup 1) ^{\*} = \Sigma ^{\*} }$ gives all strings over ${ \Sigma = \lbrace 0, 1 \rbrace }.$ Expression ${ \Sigma ^{\*} 1 }$ gives all strings that end in ${ 1 }.$ Expression ${ \Sigma ^{\*} 1 1 \Sigma ^{\*} }$ gives all strings that contain ${ 1 1 .}$ (These are regular languages, not a coincidence). 

Goal: Show finite automata are equivalent to regular expressions. 

We’ll show regular languages are closed under finite ${ \cup },$ ${ \circ }$ and ${ (\cdots) ^{*}. }$ 

**Thm**: If ${ A _1, A _2 }$ are regular languages, so is ${ A _1 \cup A _2 }.$   
**Sketch**: Say ${ M _1 }$ ${ = (Q _1, \Sigma, \delta _1, q _1, F _1 ) }$ recognises ${ A _1 }$ and ${ M _2 = }$ ${ (Q _2, \Sigma, \delta _2, q _2, F _2) }$ recognises ${ A _2 }.$ Consider ${ M = (Q, \Sigma, \delta, q _0, F) }$ with states ${ Q = Q _1  \times Q _2 },$ transition function ${ \delta((r _1, r _2), a) = (\delta _1 (r _1, a), \delta _2 (r _2, a)), }$ start state ${ q _0 = (q _1, q _2) }$ and accept states ${ F = (F _1 \times Q _2) \cup (Q _1 \times F _2) }.$ The automaton ${ M }$ recognises ${ A _1 \cup A _2 }.$ 

**Lec-2**: 

Goal: Show finite automata are equivalent to regular expressions. 

**Thm**: If ${ A _1, A _2 }$ are regular languages, so is ${ A _1 A _2 .}$   
**Sketch**: Say finite automaton ${ M _1 }$ recognises ${ A _1 ,}$ and ${ M _2 }$ recognises ${ A _2 }.$ Attempting to connect accept states of ${ M _1 }$ to start state of ${ M _2 }$ doesn’t really work. Needs a new concept, Non-determinism. 

Features of non-determinism: 
* Multiple paths possible (${ 0 },$ ${ 1 }$ or many choices at each step)
* An ${ \varepsilon -}$transition is a “free move” without reading any symbol
* Accept input if some path leads to an accept state.

Non-determinism doesn’t correspond to a physical machine that can be built, but is useful mathematically. 

A **nondeterministic finite automaton** (NFA) is a ${ 5 - }$tuple ${ (Q, \Sigma, \delta, q _0, F) },$ with everything same as a finite automaton except the transition function being ${ \delta : Q \times \Sigma _{\varepsilon} \to \mathcal{P}(Q) }$ (where ${ \Sigma _{\varepsilon} = \Sigma \cup \lbrace \varepsilon \rbrace }$). 

The notion of accepting a string is modified accordingly. An NFA ${ N = (Q, \Sigma, \delta, q _0, F) }$ **accepts string** ${ w = w _1 \ldots w _n }$ (each ${ w _i \in \Sigma _{\varepsilon} }$) if there is a sequence of states ${ r _0, \ldots, r _n \in Q }$ such that: 
* ${ r _0 = q _0 }$ 
* ${ r _i  \in  \delta(r _{i-1}, w _i) }$ for ${ 1 \leq i \leq n }$ 
* ${ r _n \in F }.$ 

**Thm** [Converting NFAs to DFAs]:   
If an NFA recognises ${ A }$ then ${ A }$ is regular.   
**Sketch**: Say ${ N = (Q, \Sigma , \delta, q _0, F) }$ is an NFA recognizing ${ A. }$ We want a DFA ${ M = (Q ^{‘}, \Sigma, \delta ^{‘}, q _0 ^{‘}, F ^{‘}) }$ that recognizes ${ A .}$   
Say the **states of DFA** are ${ Q ^{‘} = \mathcal{P}(Q) }.$ Given a state ${ R \in Q ^{‘} ,}$ we can consider its ${ \varepsilon-}$expansion (although the DFA should have no ${ \varepsilon -}$transitions) to be $${ E(R) = \lbrace q \in Q \vert q \text{ can be reached from } R \text{ by going along } 0 \text{ or more } \varepsilon \text{-arrows} \rbrace .}$$ Say the **start state of DFA** is ${ E(\lbrace q _0 \rbrace) }.$ To construct the transition function of the DFA… first consider ${ \hat{\delta} : Q ^{‘} \times \Sigma \to Q ^{‘} }$ where ${ \hat{\delta}(R, a) = \cup _{r \in R} \delta(r, a) }$ (That is, all points of NFA that can be reached by starting at an ${ r \in R }$ and reading the symbol ${ a (\neq \varepsilon) \in \Sigma }$). Now the actual **transition function of DFA** is ${ \delta ^{‘} : Q ^{‘} \times \Sigma \to Q ^{‘} }$ where ${ \delta ^{‘} (R, a) = E( \hat{\delta}(E(R), a)) .}$ That is, to read a symbol ${ a \in \Sigma, }$ expand the state, read ${ a }$ in the sense of ${ \hat{\delta} ,}$ and expand the result. Say the **accept states of DFA** are $${ F ^{‘} = \lbrace R \in Q ^{‘} \vert R \text{ contains an accept state of NFA } N \rbrace .}$$   
We see this DFA ${ M }$ recognises the same language as the NFA ${ N }$. (At every step in the computation of ${ M }$ on an input, it enters a state corresponding to the subset of states that  ${ N }$ could be in at that point).  

That regular languages are closed under (finite) union can be proved again using NFAs. 

**Thm**: If ${ A _1, A _2 }$ are regular languages so is ${ A _1 \cup A _2 .}$   
**Sketch**: Say DFAs ${ M _1 }$ and ${ M _2 }$ recognize ${ A _1 }$ and ${ A _2 }$ respectively. It suffices to construct an NFA recognizing ${ A _1 \cup A _2 .}$ For the NFA: put the DFAs ${ M _1, M _2 }$ side by side, add a new start state, add ${ \varepsilon-}$transitions from the new start state to the start states of ${ M _1 }$ and ${ M _2 }.$ Remove start labels of ${ M _1, M _2 .}$ This NFA recognizes ${ A _1 \cup A _2 .}$ 

**Thm**: If ${ A _1, A _2 }$ are regular languages so is ${ A _1 A _2. }$   
**Sketch**: Say DFAs ${ M _1 }$ and ${ M _2 }$ recognize ${ A _1 }$ and ${ A _2 }$ respectively. It suffices to construct an NFA recognizing ${ A _1 A _2 .}$ For the NFA: put the DFAs ${ M _1, M _2 }$ one after the other, add ${ \varepsilon -}$transitions from accept states of ${ M _1 }$ to start state of ${ M _2 .}$ Remove the accept labels of ${ M _1 }$ and start label of ${ M _2 .}$ This NFA recognizes ${ A _1 A _2 .}$ 

**Thm**: If ${ A }$ is a regular language, so is ${ A ^{\*} .}$   
**Sketch**: Say DFA ${ M }$ recognizes ${ A .}$ It suffices to construct an NFA recognizing ${ A ^{\*} .}$ For the NFA: add ${ \varepsilon-}$transitions from accept states to the start state, add a new start state and an ${ \varepsilon-}$transition from new start state to old start state. Remove start label from old start state, and add accept label to new start state. This NFA recognizes ${ A ^{\*} .}$ 

**Thm**: If ${ R }$ is a regular expression and ${ A = L(R), }$ then ${ A }$ is regular.   
**Sketch**: ([Lecture](https://youtu.be/oNsscmUwjMU?si=Q5eeT8POlWFR8HF8) at 56:00) The NFA which recognizes ${ A }$ follows from above closure constructions. 

**Lec-3**: 

We will show: If ${ A }$ is regular then ${ A = L(R) }$ for some regular expression ${ R .}$ (That is, regular languages are equivalent to regular expressions). 

A **generalized NFA** (GNFA) is similar to an NFA, but allows **regular expressions as transition labels**. 

For convenience, we require that GNFAs always have a special form:   
* The start state has arrows going out to every other state but no arrows coming in from any other state. 
* There is a single accept state, and it has arrows coming in from every other state but no arrows going out to any other state. 
* Accept state and start state are different. 
* Except for the start and accept states, one arrow goes from every state to every other state and also from each state to itself. 

So formally, a **generalized NFA** (GNFA) is a ${5-}$tuple ${ (Q, \Sigma, \delta, q _{\text{start}}, q _{\text{accept}}) }$ where:   
* ${ Q }$ is the finite set of states
* ${ \Sigma }$ is the input alphabet 
* ${ \delta : (Q - \lbrace q _{\text{accept}} \rbrace) \times (Q - \lbrace q _{\text{start}} \rbrace) \longrightarrow \mathcal{R}, }$ where ${ \mathcal{R} }$ is the set of all regular expressions over ${ \Sigma ,}$ is the transition function 
* ${ q _{\text{start}} }$ is the start state 
* ${ q _{\text{accept}} }$ is the accept state. 

A GNFA **accepts a string** ${ w \in \Sigma ^{\*} }$ if there is a decomposition ${ w = w _1 \ldots w _k }$ (each ${ w _i \in \Sigma ^{\*} }$) and a sequence of states ${ q _0, q _1, \ldots, q _k }$ such that:   
* ${ q _0 = q _{\text{start}} }$ is the start state 
* ${ q _k = q _{\text{accept}} }$ is the accept state 
* For each ${ i , }$ ${ w _i \in L(R _i) }$ where ${ R _i = \delta(q _{i-1}, q _i) .}$ 

We can easily convert a DFA to a GNFA in special form:   
* Add a new start state with an ${ \varepsilon -}$arrow to old start state. Add a new accept state with ${ \varepsilon -}$arrows from old accept states. Remove old start and accept labels. 
* If there are multiple arrows from one state to another, replace with a single arrow having union of previous labels. Add arrows labelled ${ \emptyset }$ between states that had no arrows.

We can convert a GNFA into a regular expression.   
**Sketch**: Say the GNFA has ${ k }$ states. Since there are atleast the start and accept states, ${ k \geq 2 .}$ If ${ k > 2 }$ we will construct an equivalent GNFA with ${ k-1 }$ states. (Continuing so, if ${ k = 2 }$ the GNFA has a single arrow from the start state to accept state. The label of this arrow is the equivalent regular expression). The removal of one state is done as follows:   
As ${ k > 2 }$ pick a state ${ q _{\text{rip}} \in Q }$ different from ${ q _{\text{start}} }$ and ${ q _{\text{accept}} }.$ We rip out ${ q _{\text{rip}}, }$ and repair the remainder so that the same language is still recognized. In the old machine, if we had arrows ${ q _i \overset{R _1}{\longrightarrow} q _{\text{rip}} ;}$ ${ q _{\text{rip}} \overset{R _2}{\longrightarrow} q _{\text{rip}} ;}$ ${ q _{\text{rip}} \overset{R _3}{\longrightarrow} q _j }$ and ${ q _i \overset{R _4}{\longrightarrow} q _j ,}$ then in the new machine the arrow from ${ q _i }$ to ${ q _j }$ gets the label ${ R _1 R _2 ^{*} R _3 \cup R _4 .}$ We make this change for each arrow going from any state ${ q _i }$ to any state ${ q _j }$ (including the case ${ q _i = q _j }$). The new machine now recognizes the original language.

Pumping lemma helps see if a language is non-regular.   

**Pumping lemma**: For every regular language ${ A ,}$ there is a number ${ p }$ (called “pumping length”) such that if ${ s \in A }$ and ${ \vert s \vert \geq p }$ then ${ s = xyz }$ where   
* ${ x y ^{i} z \in A }$ for all ${ i \geq 0 }$ (this is the pumping part) 
* ${ y \neq \varepsilon }$ 
* ${ \vert xy \vert \leq p .}$   

Informally: ${ A }$ is regular ${ \implies }$ every long string in ${ A }$ can be pumped and the result stays in ${ A .}$   

**Sketch**: Let DFA ${ M = (Q, \Sigma, \delta, q _1, F) }$ recognize ${ A .}$ Set ${ p = \vert Q \vert, }$ the number of states in ${ M .}$   
Now consider any string ${ s = s _1 \ldots s _n \in A }$ of length ${ n \geq p .}$ On processing string ${ s ,}$ say ${ M }$ enters the sequence of states ${ r _1 \overset{s _1}{\longrightarrow} r _2 \longrightarrow \ldots \longrightarrow r _n \overset{s _n}{\longrightarrow} r _{n+1} .}$ The sequence of states ${ r _1 \ldots r _{n+1} }$ has length ${ n + 1 \geq p + 1 ,}$ and there are ${ p }$ distinct states in ${ M .}$ So some ${ r _j = r _l }$ with ${ j < l \leq p + 1 .}$   
Now ${ r _1 \overset{s _1 \ldots s _{j-1}}{\longrightarrow} r _{j} \overset{s _j \ldots s _{l-1}}{\longrightarrow} r _l (= r _j) \overset{s _l \ldots s _n}{\longrightarrow} r _{n+1} .}$ So writing the string ${ s = s _1 \ldots s _n }$ as ${ s = \underbrace{s _1 \ldots s _{j-1}} _{x} \, \underbrace{s _j \ldots s _{l -1} } _{y} \underbrace{s _l \ldots s _n} _{z} }$ gives the required decomposition:   
* ${ x y ^{i} z \in A }$ for all ${ i \geq 0 }$  
* ${ y \neq \varepsilon, }$ as ${ j < l }$ 
* ${ \vert xy \vert \leq p ,}$ as ${ l \leq p + 1 .}$

**Eg**: The language ${ D = \lbrace 0 ^k 1 ^k \vert k \geq 0 \rbrace }$ is not regular.   
**Sketch**: Say the language ${ D }$ were regular. Then there is a pumping length ${ p .}$ Now consider the string ${ s = 0 ^p 1 ^p \in D.}$   
Pumping lemma says we can write ${ s }$ as ${ s = xyz }$ with properties as above. As ${ \vert xy \vert \leq p ,}$ substring ${ xy }$ is just ${ 0 }$s (and ${ y \neq \varepsilon }$). But now ${ x y ^{2} z }$ has more ${ 0 }$s than ${ 1 }$s, so ${ x y ^{2} z \notin D ,}$ a contradiction.   
Hence ${ D }$ is not regular. 

**Eg**: Consider ${ F = \lbrace w ^2 \vert w \in \Sigma ^{*} \rbrace }$ with ${ \Sigma = \lbrace 0, 1 \rbrace .}$ The language ${ F }$ is not regular.   
**Sketch**: Say the language ${ F }$ were regular. Then there is a pumping length ${ p .}$ Now consider the string ${ s = 0 ^p 1 0 ^p 1 \in F . }$   
Pumping lemma says we can write ${ s }$ as ${ s = xyz }$ with properties as above. As ${ \vert xy \vert \leq p, }$ the substring ${ xy }$ is just ${ 0 }$s (and ${ y \neq \varepsilon }$). Now ${ \underbrace{xy ^2} _{\text{just } 0s} z \notin F ,}$ a contradiction.   
Hence ${ F }$ is not regular. 

**Eg**: Consider ${ B = \lbrace w \vert w \text{ has equal number of } 0s \text{ and } 1s \rbrace }$ over symbols ${ \Sigma = \lbrace 0, 1 \rbrace .}$ The language ${ B }$ is not regular.   
**Sketch**: Say the language ${ B }$ were regular. Now ${ B \cap 0 ^{\*} 1 ^{\*} = \lbrace 0 ^k 1 ^k \vert k \geq 0 \rbrace }$ is regular. But we already showed ${ \lbrace 0 ^k 1 ^k \vert k \geq 0 \rbrace }$ is not regular, a contradiction.   
Hence ${ B }$ is not regular. 

**Lec-4**: 

An example of a context free grammar (CFG) is ${ G _1 }$ given by: 

$${ S \to 0S1 }$$ 

$${ S \to R }$$ 

$${ R \to \varepsilon. }$$ 

A grammar consists of a collection of **substitution rules**. Each rule appears as a line, comprising of a symbol and a string separated by an arrow. Here the symbol is called a **variable**. The string consists of variables and other symbols called **terminals**. The top left variable is the **start variable**. 

A CFG describes a language by generating each string of that language as follows:   
* Write down the start variable (i.e. top left variable).
* Find a variable that is written down and a rule which starts with that variable. Replace the written down variable with right hand side of that rule. 
* Repeat above step until no variables remain. 

